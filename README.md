# NCTU_VRDL_HW2
NCTU Visual Recognition using Deep Learning HW2

## Hardware
The following specs were used to create the original solution.

Ubuntu 18.04.3 LTS
Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz
3x GeForce RTX 2080 TI

## Reproducing Submission
To reproduct my submission without retrainig, do the following steps:
1. [Introduction](#Introduction)
2. [Installation](#installation)
3. [Dataset Preparation](#Dataset-Preparation)
4. [Training](#Training) detail.
5. [Testing](#Testing) detail.
6. [Reference](#Reference)

## Introduction
This work is for SVHN-dataset (Street View House Number) benchmark digits-detection and digits-classification.
For the model part, we use YOLO-v3 as our backbone. We reference the code generated by [Erik Linder-NorÃ©n](https://github.com/eriklindernoren).
Here's the original code, [PyTorch-YOLOv3](https://github.com/eriklindernoren/PyTorch-YOLOv3).

## Installation

this code was trained and tested with Python 3.6.10 and Pytorch 1.2.0 (Torchvision 0.4.0) on Ubuntu 18.04

```
conda create -n hpa python=3.6
conda activate hpa
$ git clone https://github.com/eriklindernoren/PyTorch-YOLOv3
$ cd PyTorch-YOLOv3/
$ sudo pip3 install -r requirements.txt
numpy
torch>=1.0
torchvision
matplotlib
tensorflow
tensorboard
terminaltables
pillow
tqdm
```

## Dataset Preparation
Run the code generate_data.py to prepare the dataset.
We follow the coco dataset, convert our label data into coco dataset formatt.
We seperate the original training data(33402 images) into two part. One for training(23402 images) and one for evaluating(10000 images).
We also have testing data(13068 images) for testing.
```
$ python generate_data.py
```
We will obtain ```data/custom/train.txt``` and ```data/custom/val.txt``` for all the data path of training and evaluating.
```
# train.txt
data/custom/images/1.png
data/custom/images/2.png
...
...
```
We will also obtain the annotation txt files in the data/custom/labels/. The coordinates are normalized into ```[0, 1]```.
the ```classes.names``` file is for the label name.
```
# image_name.txt
label_idx x_center y_center width height
```
Put the testing data in ```data/samples/```
All required files in the directory.
```
PyTorch-YOLOv3
  +- config
  |  +-yolov3-custom.cfg
  |  +-custom.data
  +- data
  |  +-custom
     | +- images
       |  +- (all images)
     | +- labels
       |  +- (all annotations)
     |- train.txt
     |- val.txt
     |- classes.names
  |  +-samples
     | +- (all test images)
```

## Training
To train models, run following commands.
```
$ python train.py --model_def config/yom.cfg --data_config config/custom.data --pretrained_weights weights/darknet53.conv.74
```
### Download pretrained weights
```
$ cd weights/
$ bash download_weights.sh
```
The expected training times are:
Model | GPUs | Image size | Training Epochs | Training Time
------------ | ------------- | ------------- | ------------- | -------------
YOLOv3-Pytorch | 3x RTX 2080Ti | 416 x 416 | 60 | 10 hours

## Testing
To train models, run following commands.
```
python3 detect.py --image_folder data/samples/
```
Finally input the file path of the [checkpoint](https://drive.google.com/file/d/1WzD0tFEfOlN4pLIaJGZ9t7uZY_1ubReC/view?usp=sharing)

After testing the result will be generate in the output folder.

## Reference
1. [PyTorch-YOLOv3](https://github.com/eriklindernoren/PyTorch-YOLOv3).
2. [pytorch-YOLOv4](https://github.com/Tianxiaomo/pytorch-YOLOv4).
